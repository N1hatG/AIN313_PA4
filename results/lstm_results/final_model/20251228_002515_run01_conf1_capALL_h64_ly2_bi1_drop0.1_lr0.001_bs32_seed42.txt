=== LSTM (Pose Sequence Classification) ===
 
[Hyperparameters]
{
  "RANDOM_SEED": 42,
  "USE_CONF": true,
  "MAX_TRAIN_PER_CLASS": null,
  "test_size": 0.2,
  "val_split": 0.15,
  "weight_decay": 0.0001,
  "grad_clip_norm": 5.0,
  "early_stopping_patience": 20,
  "LSTM_HIDDEN": 64,
  "LSTM_LAYERS": 2,
  "BIDIRECTIONAL": true,
  "DROPOUT": 0.1,
  "LR": 0.001,
  "BATCH_SIZE": 32,
  "MAX_EPOCHS": 60,
  "BEST_VAL_ACC": 0.875,
  "BEST_EPOCH": 43,
  "EPOCHS_RUN": 60,
  "CHECKPOINT_PATH": "C:\\Users\\User\\Desktop\\AIN313_PA4\\results\\lstm_results\\final_model\\20251228_002515_run01_conf1_capALL_h64_ly2_bi1_drop0.1_lr0.001_bs32_seed42.pt",
  "MACRO_F1": 0.8428710497639447,
  "WEIGHTED_F1": 0.8428710497639447,
  "TOP_CONFUSIONS": "running -> jogging : 7\nwalking -> jogging : 4\njogging -> running : 4\nwalking -> boxing : 2\njogging -> walking : 1\nhandwaving -> handclapping : 1",
  "PER_CLASS_TABLE": "class            prec    rec     f1   supp\n------------------------------------------\nboxing          0.909  1.000  0.952     20\nhandclapping    0.952  1.000  0.976     20\nhandwaving      1.000  0.950  0.974     20\njogging         0.577  0.750  0.652     20\nrunning         0.765  0.650  0.703     20\nwalking         0.933  0.700  0.800     20",
  "TRAINING_CURVES": "epoch    tr_loss   tr_acc    va_loss   va_acc\n----------------------------------------------\n    1     1.6180   0.4226     1.3586   0.5139\n    2     1.1414   0.5799     0.9652   0.6389\n    3     0.8237   0.7174     0.7655   0.7083\n    4     0.6375   0.7912     0.6374   0.7361\n    5     0.4887   0.8403     0.5679   0.7639\n    6     0.4072   0.8649     0.5560   0.8194\n    7     0.2887   0.9386     0.4573   0.8194\n    8     0.2094   0.9459     0.4939   0.8056\n    9     0.2181   0.9312     0.4344   0.8194\n   10     0.1492   0.9730     0.4854   0.8194\n   11     0.1401   0.9705     0.4717   0.8194\n   12     0.0942   0.9853     0.4746   0.7500\n   13     0.1021   0.9730     0.4754   0.8194\n   14     0.0774   0.9803     0.4760   0.7917\n   15     0.0724   0.9828     0.5305   0.7778\n   16     0.0682   0.9853     0.4717   0.8056\n   17     0.0622   0.9902     0.5100   0.8194\n   18     0.0404   0.9951     0.4836   0.8333\n   19     0.0520   0.9902     0.5652   0.8056\n   20     0.0408   0.9975     0.4798   0.7917\n   21     0.0289   0.9951     0.5221   0.7917\n   22     0.0306   0.9902     0.4767   0.8056\n   23     0.0313   0.9902     0.4530   0.8333\n   24     0.0351   0.9902     0.4735   0.8333\n   25     0.0310   0.9951     0.5156   0.8333\n   26     0.0178   0.9951     0.5533   0.8194\n   27     0.0323   0.9877     0.5510   0.8194\n   28     0.0235   0.9951     0.5181   0.8472\n   29     0.0303   0.9902     0.5205   0.8333\n   30     0.0231   0.9951     0.5666   0.8056\n   31     0.0615   0.9828     0.5110   0.8333\n   32     0.0413   0.9902     0.6003   0.8472\n   33     0.0960   0.9730     0.4568   0.8333\n   34     0.0703   0.9754     0.5513   0.7500\n   35     0.0851   0.9705     0.6517   0.7917\n   36     0.1374   0.9631     0.4551   0.7917\n   37     0.0810   0.9705     0.4617   0.8056\n   38     0.0493   0.9877     0.4957   0.7917\n   39     0.0438   0.9902     0.4495   0.8472\n   40     0.0332   0.9902     0.4213   0.8472\n   41     0.0276   0.9951     0.4670   0.8194\n   42     0.0274   0.9926     0.4198   0.8194\n   43     0.0246   0.9926     0.3313   0.8750\n   44     0.0388   0.9926     0.3236   0.8750\n   45     0.0265   0.9902     0.2948   0.8611\n   46     0.0119   1.0000     0.3158   0.8611\n   47     0.0101   0.9975     0.3130   0.8472\n   48     0.0097   1.0000     0.3190   0.8750\n   49     0.0076   0.9975     0.3277   0.8472\n   50     0.0073   1.0000     0.3298   0.8611\n   51     0.0077   0.9975     0.3333   0.8472\n   52     0.0102   0.9975     0.3248   0.8611\n   53     0.0119   0.9951     0.3777   0.8750\n   54     0.0267   0.9877     0.3011   0.8611\n   55     0.0111   0.9975     0.2970   0.8750\n   56     0.0083   0.9951     0.3104   0.8611\n   57     0.0038   1.0000     0.3273   0.8472\n   58     0.0025   1.0000     0.3351   0.8611\n   59     0.0022   1.0000     0.3369   0.8611\n   60     0.0020   1.0000     0.3352   0.8750"
}
 
[Split / Data]
{
  "total_files": 599,
  "train_files_before_cap": 479,
  "test_files": 120,
  "train_sequences_after_cap": 479,
  "class_names": [
    "boxing",
    "handclapping",
    "handwaving",
    "jogging",
    "running",
    "walking"
  ]
}
 
[Timings (seconds)]
{
  "load_data": 0.4571,
  "train_fit": 105.4354,
  "eval": 0.2773,
  "total": 106.1699
}
 
[Accuracy]
0.841667

[Confusion Matrix]
            BX    HC    HW    JG    RN    WK
BX     |    20     0     0     0     0     0
HC     |     0    20     0     0     0     0
HW     |     0     1    19     0     0     0
JG     |     0     0     0    15     4     1
RN     |     0     0     0     7    13     0
WK     |     2     0     0     4     0    14
 
[Classification Report]
              precision    recall  f1-score   support

      boxing     0.9091    1.0000    0.9524        20
handclapping     0.9524    1.0000    0.9756        20
  handwaving     1.0000    0.9500    0.9744        20
     jogging     0.5769    0.7500    0.6522        20
     running     0.7647    0.6500    0.7027        20
     walking     0.9333    0.7000    0.8000        20

    accuracy                         0.8417       120
   macro avg     0.8561    0.8417    0.8429       120
weighted avg     0.8561    0.8417    0.8429       120

Macro F1: 0.8428710497639447
Weighted F1: 0.8428710497639447
 
[Top Confusions]
running -> jogging : 7
walking -> jogging : 4
jogging -> running : 4
walking -> boxing : 2
jogging -> walking : 1
handwaving -> handclapping : 1
 
[Per-class Table]
class            prec    rec     f1   supp
------------------------------------------
boxing          0.909  1.000  0.952     20
handclapping    0.952  1.000  0.976     20
handwaving      1.000  0.950  0.974     20
jogging         0.577  0.750  0.652     20
running         0.765  0.650  0.703     20
walking         0.933  0.700  0.800     20
 
[Training Curves]
epoch    tr_loss   tr_acc    va_loss   va_acc
----------------------------------------------
    1     1.6180   0.4226     1.3586   0.5139
    2     1.1414   0.5799     0.9652   0.6389
    3     0.8237   0.7174     0.7655   0.7083
    4     0.6375   0.7912     0.6374   0.7361
    5     0.4887   0.8403     0.5679   0.7639
    6     0.4072   0.8649     0.5560   0.8194
    7     0.2887   0.9386     0.4573   0.8194
    8     0.2094   0.9459     0.4939   0.8056
    9     0.2181   0.9312     0.4344   0.8194
   10     0.1492   0.9730     0.4854   0.8194
   11     0.1401   0.9705     0.4717   0.8194
   12     0.0942   0.9853     0.4746   0.7500
   13     0.1021   0.9730     0.4754   0.8194
   14     0.0774   0.9803     0.4760   0.7917
   15     0.0724   0.9828     0.5305   0.7778
   16     0.0682   0.9853     0.4717   0.8056
   17     0.0622   0.9902     0.5100   0.8194
   18     0.0404   0.9951     0.4836   0.8333
   19     0.0520   0.9902     0.5652   0.8056
   20     0.0408   0.9975     0.4798   0.7917
   21     0.0289   0.9951     0.5221   0.7917
   22     0.0306   0.9902     0.4767   0.8056
   23     0.0313   0.9902     0.4530   0.8333
   24     0.0351   0.9902     0.4735   0.8333
   25     0.0310   0.9951     0.5156   0.8333
   26     0.0178   0.9951     0.5533   0.8194
   27     0.0323   0.9877     0.5510   0.8194
   28     0.0235   0.9951     0.5181   0.8472
   29     0.0303   0.9902     0.5205   0.8333
   30     0.0231   0.9951     0.5666   0.8056
   31     0.0615   0.9828     0.5110   0.8333
   32     0.0413   0.9902     0.6003   0.8472
   33     0.0960   0.9730     0.4568   0.8333
   34     0.0703   0.9754     0.5513   0.7500
   35     0.0851   0.9705     0.6517   0.7917
   36     0.1374   0.9631     0.4551   0.7917
   37     0.0810   0.9705     0.4617   0.8056
   38     0.0493   0.9877     0.4957   0.7917
   39     0.0438   0.9902     0.4495   0.8472
   40     0.0332   0.9902     0.4213   0.8472
   41     0.0276   0.9951     0.4670   0.8194
   42     0.0274   0.9926     0.4198   0.8194
   43     0.0246   0.9926     0.3313   0.8750
   44     0.0388   0.9926     0.3236   0.8750
   45     0.0265   0.9902     0.2948   0.8611
   46     0.0119   1.0000     0.3158   0.8611
   47     0.0101   0.9975     0.3130   0.8472
   48     0.0097   1.0000     0.3190   0.8750
   49     0.0076   0.9975     0.3277   0.8472
   50     0.0073   1.0000     0.3298   0.8611
   51     0.0077   0.9975     0.3333   0.8472
   52     0.0102   0.9975     0.3248   0.8611
   53     0.0119   0.9951     0.3777   0.8750
   54     0.0267   0.9877     0.3011   0.8611
   55     0.0111   0.9975     0.2970   0.8750
   56     0.0083   0.9951     0.3104   0.8611
   57     0.0038   1.0000     0.3273   0.8472
   58     0.0025   1.0000     0.3351   0.8611
   59     0.0022   1.0000     0.3369   0.8611
   60     0.0020   1.0000     0.3352   0.8750
 
