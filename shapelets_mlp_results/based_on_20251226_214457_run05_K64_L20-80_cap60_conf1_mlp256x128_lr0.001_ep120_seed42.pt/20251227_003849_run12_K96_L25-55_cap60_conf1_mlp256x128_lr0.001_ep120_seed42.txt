=== Shapelets + MLP (Random Shapelet Transform) ===
 
[Hyperparameters]
{
  "RANDOM_SEED": 42,
  "USE_CONF": true,
  "NUM_SHAPELETS": 96,
  "LEN_MIN": 25,
  "LEN_MAX": 55,
  "MAX_TRAIN_PER_CLASS": 60,
  "MLP_HIDDEN": [
    256,
    128
  ],
  "MLP_MAX_ITER": 120,
  "MLP_LR": 0.001,
  "test_size": 0.2,
  "val_split": 0.15,
  "batch_size": 128,
  "weight_decay": 0.0001,
  "dropout": 0.2,
  "early_stopping_patience": 12,
  "BEST_VAL_ACC": 0.7592592592592593,
  "BEST_EPOCH": 45,
  "EPOCHS_RUN": 57,
  "CHECKPOINT_PATH": "C:\\Users\\User\\Desktop\\AIN313_PA4\\shapelets_mlp_results\\based_on_20251226_214457_run05_K64_L20-80_cap60_conf1_mlp256x128_lr0.001_ep120_seed42.pt\\20251227_003849_run12_K96_L25-55_cap60_conf1_mlp256x128_lr0.001_ep120_seed42.pt",
  "MACRO_F1": 0.7045173435417338,
  "WEIGHTED_F1": 0.7045173435417339,
  "TOP_CONFUSIONS": "walking -> jogging : 8\njogging -> running : 8\nwalking -> running : 4\nrunning -> jogging : 4\njogging -> walking : 3\nhandclapping -> handwaving : 3\nrunning -> walking : 2\nhandwaving -> handclapping : 2\nrunning -> boxing : 1",
  "PER_CLASS_TABLE": "class            prec    rec     f1   supp\n------------------------------------------\nboxing          0.952  1.000  0.976     20\nhandclapping    0.895  0.850  0.872     20\nhandwaving      0.857  0.900  0.878     20\njogging         0.429  0.450  0.439     20\nrunning         0.520  0.650  0.578     20\nwalking         0.615  0.400  0.485     20",
  "TRAINING_CURVES": "epoch    tr_loss   tr_acc    va_loss   va_acc\n----------------------------------------------\n    1     1.7184   0.3301     1.5595   0.4444\n    2     1.5049   0.5327     1.3760   0.4815\n    3     1.3146   0.5163     1.2169   0.4815\n    4     1.1484   0.5458     1.1086   0.4815\n    5     1.0238   0.5458     1.0478   0.5000\n    6     0.9587   0.5229     1.0063   0.5370\n    7     0.9088   0.5621     0.9743   0.5370\n    8     0.8572   0.6176     0.9371   0.5556\n    9     0.8292   0.5915     0.8981   0.5926\n   10     0.8145   0.6340     0.8595   0.5926\n   11     0.7721   0.6340     0.8286   0.5556\n   12     0.7506   0.6503     0.8152   0.6111\n   13     0.7369   0.6503     0.8099   0.6296\n   14     0.7316   0.6307     0.7532   0.5926\n   15     0.6989   0.6699     0.7433   0.6111\n   16     0.6763   0.6928     0.7376   0.6111\n   17     0.6791   0.6797     0.7392   0.6296\n   18     0.6448   0.7484     0.7160   0.6111\n   19     0.6413   0.7288     0.6784   0.6296\n   20     0.6156   0.7222     0.6723   0.6111\n   21     0.6138   0.7386     0.7073   0.6296\n   22     0.6242   0.7157     0.7013   0.6296\n   23     0.5953   0.7386     0.6778   0.6296\n   24     0.5730   0.7484     0.6495   0.6296\n   25     0.5740   0.7516     0.6491   0.6481\n   26     0.5313   0.7614     0.6767   0.6296\n   27     0.5535   0.7320     0.6848   0.6296\n   28     0.5313   0.8007     0.6364   0.6481\n   29     0.5300   0.7974     0.6330   0.6667\n   30     0.5220   0.7843     0.6338   0.7037\n   31     0.4962   0.8268     0.6507   0.6481\n   32     0.4912   0.7941     0.6785   0.6481\n   33     0.4983   0.8072     0.6326   0.6667\n   34     0.4703   0.8039     0.6408   0.6852\n   35     0.4681   0.8137     0.6398   0.7037\n   36     0.4519   0.8268     0.6589   0.6667\n   37     0.4441   0.8399     0.6532   0.7037\n   38     0.4391   0.8170     0.6600   0.6667\n   39     0.4366   0.8170     0.6503   0.6852\n   40     0.4229   0.8170     0.6605   0.7037\n   41     0.4301   0.8399     0.6422   0.7222\n   42     0.3811   0.8758     0.6371   0.7222\n   43     0.3938   0.8464     0.6444   0.7407\n   44     0.3705   0.8464     0.6640   0.7222\n   45     0.3817   0.8497     0.6333   0.7593\n   46     0.3803   0.8562     0.6444   0.7407\n   47     0.3567   0.8758     0.6616   0.7222\n   48     0.3651   0.8366     0.6689   0.7037\n   49     0.3432   0.8693     0.6586   0.7222\n   50     0.3611   0.8529     0.6784   0.7407\n   51     0.3547   0.8497     0.7053   0.7037\n   52     0.3620   0.8399     0.7122   0.7037\n   53     0.3397   0.8791     0.7034   0.7222\n   54     0.3656   0.8627     0.6965   0.7037\n   55     0.3195   0.8725     0.7337   0.6852\n   56     0.3449   0.8562     0.7250   0.7222\n   57     0.3240   0.8627     0.7206   0.7037"
}
 
[Split / Data]
{
  "total_files": 599,
  "train_files_before_cap": 479,
  "test_files": 120,
  "train_sequences_after_cap": 360,
  "class_names": [
    "boxing",
    "handclapping",
    "handwaving",
    "jogging",
    "running",
    "walking"
  ]
}
 
[Timings (seconds)]
{
  "load_data": 0.4444,
  "sample_shapelets": 0.0036,
  "transform_train": 268.6076,
  "transform_test": 86.8585,
  "mlp_fit": 0.5924,
  "eval": 0.0057,
  "total": 356.5121
}
 
[Accuracy]
0.708333

[Confusion Matrix]
            BX    HC    HW    JG    RN    WK
BX     |    20     0     0     0     0     0
HC     |     0    17     3     0     0     0
HW     |     0     2    18     0     0     0
JG     |     0     0     0     9     8     3
RN     |     1     0     0     4    13     2
WK     |     0     0     0     8     4     8
 
[Classification Report]
              precision    recall  f1-score   support

      boxing     0.9524    1.0000    0.9756        20
handclapping     0.8947    0.8500    0.8718        20
  handwaving     0.8571    0.9000    0.8780        20
     jogging     0.4286    0.4500    0.4390        20
     running     0.5200    0.6500    0.5778        20
     walking     0.6154    0.4000    0.4848        20

    accuracy                         0.7083       120
   macro avg     0.7114    0.7083    0.7045       120
weighted avg     0.7114    0.7083    0.7045       120

Macro F1: 0.7045173435417338
Weighted F1: 0.7045173435417339
 
[Top Confusions]
walking -> jogging : 8
jogging -> running : 8
walking -> running : 4
running -> jogging : 4
jogging -> walking : 3
handclapping -> handwaving : 3
running -> walking : 2
handwaving -> handclapping : 2
running -> boxing : 1
 
[Per-class Table]
class            prec    rec     f1   supp
------------------------------------------
boxing          0.952  1.000  0.976     20
handclapping    0.895  0.850  0.872     20
handwaving      0.857  0.900  0.878     20
jogging         0.429  0.450  0.439     20
running         0.520  0.650  0.578     20
walking         0.615  0.400  0.485     20
 
[Training Curves]
epoch    tr_loss   tr_acc    va_loss   va_acc
----------------------------------------------
    1     1.7184   0.3301     1.5595   0.4444
    2     1.5049   0.5327     1.3760   0.4815
    3     1.3146   0.5163     1.2169   0.4815
    4     1.1484   0.5458     1.1086   0.4815
    5     1.0238   0.5458     1.0478   0.5000
    6     0.9587   0.5229     1.0063   0.5370
    7     0.9088   0.5621     0.9743   0.5370
    8     0.8572   0.6176     0.9371   0.5556
    9     0.8292   0.5915     0.8981   0.5926
   10     0.8145   0.6340     0.8595   0.5926
   11     0.7721   0.6340     0.8286   0.5556
   12     0.7506   0.6503     0.8152   0.6111
   13     0.7369   0.6503     0.8099   0.6296
   14     0.7316   0.6307     0.7532   0.5926
   15     0.6989   0.6699     0.7433   0.6111
   16     0.6763   0.6928     0.7376   0.6111
   17     0.6791   0.6797     0.7392   0.6296
   18     0.6448   0.7484     0.7160   0.6111
   19     0.6413   0.7288     0.6784   0.6296
   20     0.6156   0.7222     0.6723   0.6111
   21     0.6138   0.7386     0.7073   0.6296
   22     0.6242   0.7157     0.7013   0.6296
   23     0.5953   0.7386     0.6778   0.6296
   24     0.5730   0.7484     0.6495   0.6296
   25     0.5740   0.7516     0.6491   0.6481
   26     0.5313   0.7614     0.6767   0.6296
   27     0.5535   0.7320     0.6848   0.6296
   28     0.5313   0.8007     0.6364   0.6481
   29     0.5300   0.7974     0.6330   0.6667
   30     0.5220   0.7843     0.6338   0.7037
   31     0.4962   0.8268     0.6507   0.6481
   32     0.4912   0.7941     0.6785   0.6481
   33     0.4983   0.8072     0.6326   0.6667
   34     0.4703   0.8039     0.6408   0.6852
   35     0.4681   0.8137     0.6398   0.7037
   36     0.4519   0.8268     0.6589   0.6667
   37     0.4441   0.8399     0.6532   0.7037
   38     0.4391   0.8170     0.6600   0.6667
   39     0.4366   0.8170     0.6503   0.6852
   40     0.4229   0.8170     0.6605   0.7037
   41     0.4301   0.8399     0.6422   0.7222
   42     0.3811   0.8758     0.6371   0.7222
   43     0.3938   0.8464     0.6444   0.7407
   44     0.3705   0.8464     0.6640   0.7222
   45     0.3817   0.8497     0.6333   0.7593
   46     0.3803   0.8562     0.6444   0.7407
   47     0.3567   0.8758     0.6616   0.7222
   48     0.3651   0.8366     0.6689   0.7037
   49     0.3432   0.8693     0.6586   0.7222
   50     0.3611   0.8529     0.6784   0.7407
   51     0.3547   0.8497     0.7053   0.7037
   52     0.3620   0.8399     0.7122   0.7037
   53     0.3397   0.8791     0.7034   0.7222
   54     0.3656   0.8627     0.6965   0.7037
   55     0.3195   0.8725     0.7337   0.6852
   56     0.3449   0.8562     0.7250   0.7222
   57     0.3240   0.8627     0.7206   0.7037
 
