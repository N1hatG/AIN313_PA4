=== Shapelets + MLP (Random Shapelet Transform) ===
 
[Hyperparameters]
{
  "RANDOM_SEED": 42,
  "USE_CONF": true,
  "NUM_SHAPELETS": 64,
  "LEN_MIN": 40,
  "LEN_MAX": 80,
  "MAX_TRAIN_PER_CLASS": 60,
  "MLP_HIDDEN": [
    256,
    128
  ],
  "MLP_MAX_ITER": 200,
  "MLP_LR": 0.001,
  "test_size": 0.2,
  "val_split": 0.15,
  "batch_size": 128,
  "weight_decay": 0.0001,
  "dropout": 0.2,
  "early_stopping_patience": 12,
  "BEST_VAL_ACC": 0.7592592592592593,
  "BEST_EPOCH": 37,
  "EPOCHS_RUN": 49,
  "CHECKPOINT_PATH": "C:\\Users\\User\\Desktop\\AIN313_PA4\\shapelets_mlp_results\\round_3_mlp_tuning\\20251227_015311_run10_K64_L40-80_cap60_conf1_mlp256x128_lr0.001_ep200_seed42.pt",
  "MACRO_F1": 0.7895776084800475,
  "WEIGHTED_F1": 0.7895776084800475,
  "TOP_CONFUSIONS": "jogging -> running : 6\nwalking -> jogging : 4\nhandwaving -> handclapping : 4\njogging -> walking : 3\nhandclapping -> handwaving : 3\nrunning -> walking : 2\nwalking -> running : 1\nrunning -> jogging : 1\nboxing -> handwaving : 1",
  "PER_CLASS_TABLE": "class            prec    rec     f1   supp\n------------------------------------------\nboxing          1.000  0.950  0.974     20\nhandclapping    0.810  0.850  0.829     20\nhandwaving      0.800  0.800  0.800     20\njogging         0.688  0.550  0.611     20\nrunning         0.708  0.850  0.773     20\nwalking         0.750  0.750  0.750     20",
  "TRAINING_CURVES": "epoch    tr_loss   tr_acc    va_loss   va_acc\n----------------------------------------------\n    1     1.7140   0.3235     1.5724   0.5741\n    2     1.5414   0.4771     1.4038   0.5926\n    3     1.3804   0.4542     1.2562   0.5370\n    4     1.2477   0.5490     1.1353   0.5556\n    5     1.1353   0.5131     1.0384   0.5185\n    6     1.0517   0.5817     0.9661   0.5000\n    7     0.9434   0.6536     0.9068   0.5741\n    8     0.9176   0.6307     0.8593   0.5741\n    9     0.8799   0.6503     0.8271   0.5370\n   10     0.8424   0.6471     0.8028   0.5926\n   11     0.8154   0.6471     0.7819   0.5926\n   12     0.8033   0.6503     0.7631   0.6111\n   13     0.7538   0.6961     0.7595   0.6111\n   14     0.7336   0.7059     0.7315   0.6296\n   15     0.6999   0.7059     0.7146   0.6296\n   16     0.6851   0.7092     0.7063   0.6296\n   17     0.6736   0.7124     0.7074   0.6481\n   18     0.6561   0.7288     0.6830   0.6481\n   19     0.6164   0.7451     0.6638   0.6667\n   20     0.6198   0.7255     0.6515   0.6667\n   21     0.6018   0.7614     0.6695   0.6667\n   22     0.5831   0.7418     0.6672   0.6481\n   23     0.5479   0.7876     0.6237   0.7222\n   24     0.5679   0.7843     0.6227   0.7037\n   25     0.5393   0.7778     0.6323   0.6852\n   26     0.5232   0.7810     0.6023   0.6667\n   27     0.5119   0.8170     0.6083   0.6852\n   28     0.5180   0.7941     0.5898   0.7407\n   29     0.4857   0.7908     0.6035   0.7222\n   30     0.4869   0.7908     0.5935   0.7222\n   31     0.4689   0.7974     0.5622   0.7407\n   32     0.4470   0.8203     0.5606   0.7407\n   33     0.4421   0.8366     0.5658   0.7407\n   34     0.4373   0.8333     0.5544   0.7407\n   35     0.4393   0.8235     0.5797   0.7037\n   36     0.4272   0.8137     0.5779   0.7222\n   37     0.4017   0.8595     0.5737   0.7593\n   38     0.4186   0.8595     0.5696   0.7593\n   39     0.4062   0.8333     0.5936   0.7037\n   40     0.3918   0.8431     0.5736   0.7037\n   41     0.4085   0.8333     0.5472   0.7407\n   42     0.3917   0.8431     0.5568   0.7407\n   43     0.4205   0.8301     0.5817   0.7407\n   44     0.3777   0.8497     0.5637   0.7222\n   45     0.3763   0.8366     0.5448   0.7222\n   46     0.3667   0.8431     0.5394   0.7407\n   47     0.3448   0.8693     0.5719   0.7407\n   48     0.3771   0.8464     0.5504   0.7407\n   49     0.3479   0.8497     0.5260   0.7222"
}
 
[Split / Data]
{
  "total_files": 599,
  "train_files_before_cap": 479,
  "test_files": 120,
  "train_sequences_after_cap": 360,
  "class_names": [
    "boxing",
    "handclapping",
    "handwaving",
    "jogging",
    "running",
    "walking"
  ]
}
 
[Timings (seconds)]
{
  "load_data": 0.4641,
  "sample_shapelets": 0.0,
  "transform_train": 267.4806,
  "transform_test": 81.2974,
  "mlp_fit": 0.5156,
  "eval": 0.0,
  "total": 349.7577
}
 
[Accuracy]
0.791667

[Confusion Matrix]
            BX    HC    HW    JG    RN    WK
BX     |    19     0     1     0     0     0
HC     |     0    17     3     0     0     0
HW     |     0     4    16     0     0     0
JG     |     0     0     0    11     6     3
RN     |     0     0     0     1    17     2
WK     |     0     0     0     4     1    15
 
[Classification Report]
              precision    recall  f1-score   support

      boxing     1.0000    0.9500    0.9744        20
handclapping     0.8095    0.8500    0.8293        20
  handwaving     0.8000    0.8000    0.8000        20
     jogging     0.6875    0.5500    0.6111        20
     running     0.7083    0.8500    0.7727        20
     walking     0.7500    0.7500    0.7500        20

    accuracy                         0.7917       120
   macro avg     0.7926    0.7917    0.7896       120
weighted avg     0.7926    0.7917    0.7896       120

Macro F1: 0.7895776084800475
Weighted F1: 0.7895776084800475
 
[Top Confusions]
jogging -> running : 6
walking -> jogging : 4
handwaving -> handclapping : 4
jogging -> walking : 3
handclapping -> handwaving : 3
running -> walking : 2
walking -> running : 1
running -> jogging : 1
boxing -> handwaving : 1
 
[Per-class Table]
class            prec    rec     f1   supp
------------------------------------------
boxing          1.000  0.950  0.974     20
handclapping    0.810  0.850  0.829     20
handwaving      0.800  0.800  0.800     20
jogging         0.688  0.550  0.611     20
running         0.708  0.850  0.773     20
walking         0.750  0.750  0.750     20
 
[Training Curves]
epoch    tr_loss   tr_acc    va_loss   va_acc
----------------------------------------------
    1     1.7140   0.3235     1.5724   0.5741
    2     1.5414   0.4771     1.4038   0.5926
    3     1.3804   0.4542     1.2562   0.5370
    4     1.2477   0.5490     1.1353   0.5556
    5     1.1353   0.5131     1.0384   0.5185
    6     1.0517   0.5817     0.9661   0.5000
    7     0.9434   0.6536     0.9068   0.5741
    8     0.9176   0.6307     0.8593   0.5741
    9     0.8799   0.6503     0.8271   0.5370
   10     0.8424   0.6471     0.8028   0.5926
   11     0.8154   0.6471     0.7819   0.5926
   12     0.8033   0.6503     0.7631   0.6111
   13     0.7538   0.6961     0.7595   0.6111
   14     0.7336   0.7059     0.7315   0.6296
   15     0.6999   0.7059     0.7146   0.6296
   16     0.6851   0.7092     0.7063   0.6296
   17     0.6736   0.7124     0.7074   0.6481
   18     0.6561   0.7288     0.6830   0.6481
   19     0.6164   0.7451     0.6638   0.6667
   20     0.6198   0.7255     0.6515   0.6667
   21     0.6018   0.7614     0.6695   0.6667
   22     0.5831   0.7418     0.6672   0.6481
   23     0.5479   0.7876     0.6237   0.7222
   24     0.5679   0.7843     0.6227   0.7037
   25     0.5393   0.7778     0.6323   0.6852
   26     0.5232   0.7810     0.6023   0.6667
   27     0.5119   0.8170     0.6083   0.6852
   28     0.5180   0.7941     0.5898   0.7407
   29     0.4857   0.7908     0.6035   0.7222
   30     0.4869   0.7908     0.5935   0.7222
   31     0.4689   0.7974     0.5622   0.7407
   32     0.4470   0.8203     0.5606   0.7407
   33     0.4421   0.8366     0.5658   0.7407
   34     0.4373   0.8333     0.5544   0.7407
   35     0.4393   0.8235     0.5797   0.7037
   36     0.4272   0.8137     0.5779   0.7222
   37     0.4017   0.8595     0.5737   0.7593
   38     0.4186   0.8595     0.5696   0.7593
   39     0.4062   0.8333     0.5936   0.7037
   40     0.3918   0.8431     0.5736   0.7037
   41     0.4085   0.8333     0.5472   0.7407
   42     0.3917   0.8431     0.5568   0.7407
   43     0.4205   0.8301     0.5817   0.7407
   44     0.3777   0.8497     0.5637   0.7222
   45     0.3763   0.8366     0.5448   0.7222
   46     0.3667   0.8431     0.5394   0.7407
   47     0.3448   0.8693     0.5719   0.7407
   48     0.3771   0.8464     0.5504   0.7407
   49     0.3479   0.8497     0.5260   0.7222
 
