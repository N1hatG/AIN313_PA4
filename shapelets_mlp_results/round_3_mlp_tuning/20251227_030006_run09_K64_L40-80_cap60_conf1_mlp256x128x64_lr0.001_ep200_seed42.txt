=== Shapelets + MLP (Random Shapelet Transform) ===
 
[Hyperparameters]
{
  "RANDOM_SEED": 42,
  "USE_CONF": true,
  "NUM_SHAPELETS": 64,
  "LEN_MIN": 40,
  "LEN_MAX": 80,
  "MAX_TRAIN_PER_CLASS": 60,
  "MLP_HIDDEN": [
    256,
    128,
    64
  ],
  "MLP_MAX_ITER": 200,
  "MLP_LR": 0.001,
  "test_size": 0.2,
  "val_split": 0.15,
  "batch_size": 128,
  "weight_decay": 0.0001,
  "dropout": 0.2,
  "early_stopping_patience": 12,
  "BEST_VAL_ACC": 0.8333333333333334,
  "BEST_EPOCH": 35,
  "EPOCHS_RUN": 47,
  "CHECKPOINT_PATH": "C:\\Users\\User\\Desktop\\AIN313_PA4\\shapelets_mlp_results\\round_3_mlp_tuning\\20251227_030006_run09_K64_L40-80_cap60_conf1_mlp256x128x64_lr0.001_ep200_seed42.pt",
  "MACRO_F1": 0.6906751646140442,
  "WEIGHTED_F1": 0.690675164614044,
  "TOP_CONFUSIONS": "jogging -> running : 9\njogging -> walking : 6\nrunning -> walking : 5\nwalking -> running : 4\nrunning -> jogging : 4\nhandwaving -> handclapping : 4\nwalking -> jogging : 2\nhandclapping -> handwaving : 2",
  "PER_CLASS_TABLE": "class            prec    rec     f1   supp\n------------------------------------------\nboxing          1.000  1.000  1.000     20\nhandclapping    0.818  0.900  0.857     20\nhandwaving      0.889  0.800  0.842     20\njogging         0.455  0.250  0.323     20\nrunning         0.458  0.550  0.500     20\nwalking         0.560  0.700  0.622     20",
  "TRAINING_CURVES": "epoch    tr_loss   tr_acc    va_loss   va_acc\n----------------------------------------------\n    1     1.7831   0.1797     1.7287   0.2963\n    2     1.6941   0.3856     1.6392   0.4630\n    3     1.5937   0.4575     1.5215   0.5370\n    4     1.4722   0.4314     1.3956   0.5556\n    5     1.3773   0.4314     1.2920   0.5000\n    6     1.2692   0.4118     1.2091   0.6296\n    7     1.1864   0.4869     1.1372   0.6111\n    8     1.1346   0.4771     1.0735   0.6296\n    9     1.0932   0.4804     0.9892   0.6296\n   10     1.0282   0.5458     0.9022   0.6481\n   11     0.9711   0.5294     0.8477   0.7222\n   12     0.9163   0.5817     0.8069   0.7222\n   13     0.8787   0.5719     0.7544   0.7037\n   14     0.8689   0.5458     0.7227   0.6852\n   15     0.8008   0.6569     0.6974   0.6852\n   16     0.7890   0.6536     0.6792   0.7222\n   17     0.8311   0.5980     0.6612   0.7407\n   18     0.7894   0.6601     0.6381   0.7407\n   19     0.7781   0.6373     0.6302   0.7407\n   20     0.7520   0.6373     0.6224   0.7037\n   21     0.7518   0.6438     0.6106   0.7407\n   22     0.7217   0.6438     0.6006   0.7222\n   23     0.6895   0.6732     0.6061   0.7407\n   24     0.6883   0.6993     0.5965   0.7593\n   25     0.6759   0.6993     0.5766   0.7593\n   26     0.6458   0.7124     0.5632   0.7222\n   27     0.6634   0.7255     0.5626   0.7222\n   28     0.6289   0.7059     0.5491   0.7407\n   29     0.6234   0.7092     0.5371   0.7407\n   30     0.5918   0.7451     0.5434   0.7407\n   31     0.5851   0.7320     0.5332   0.7407\n   32     0.6119   0.7255     0.5156   0.8148\n   33     0.5807   0.7288     0.5029   0.7778\n   34     0.5459   0.7778     0.5100   0.7778\n   35     0.5753   0.7418     0.4887   0.8333\n   36     0.5203   0.7843     0.4777   0.7593\n   37     0.5489   0.7516     0.4826   0.7593\n   38     0.5109   0.7582     0.4667   0.7778\n   39     0.5171   0.7745     0.4978   0.7778\n   40     0.5197   0.7810     0.4572   0.7963\n   41     0.4802   0.8007     0.4597   0.8148\n   42     0.4977   0.7908     0.4523   0.7963\n   43     0.4759   0.8203     0.4618   0.7963\n   44     0.4792   0.8105     0.4613   0.8333\n   45     0.4511   0.8039     0.4534   0.8333\n   46     0.4451   0.8170     0.4733   0.7963\n   47     0.4476   0.8072     0.4887   0.7593"
}
 
[Split / Data]
{
  "total_files": 599,
  "train_files_before_cap": 479,
  "test_files": 120,
  "train_sequences_after_cap": 360,
  "class_names": [
    "boxing",
    "handclapping",
    "handwaving",
    "jogging",
    "running",
    "walking"
  ]
}
 
[Timings (seconds)]
{
  "load_data": 0.4997,
  "sample_shapelets": 0.0031,
  "transform_train": 292.5369,
  "transform_test": 101.2686,
  "mlp_fit": 0.5941,
  "eval": 0.006,
  "total": 394.9124
}
 
[Accuracy]
0.700000

[Confusion Matrix]
            BX    HC    HW    JG    RN    WK
BX     |    20     0     0     0     0     0
HC     |     0    18     2     0     0     0
HW     |     0     4    16     0     0     0
JG     |     0     0     0     5     9     6
RN     |     0     0     0     4    11     5
WK     |     0     0     0     2     4    14
 
[Classification Report]
              precision    recall  f1-score   support

      boxing     1.0000    1.0000    1.0000        20
handclapping     0.8182    0.9000    0.8571        20
  handwaving     0.8889    0.8000    0.8421        20
     jogging     0.4545    0.2500    0.3226        20
     running     0.4583    0.5500    0.5000        20
     walking     0.5600    0.7000    0.6222        20

    accuracy                         0.7000       120
   macro avg     0.6967    0.7000    0.6907       120
weighted avg     0.6967    0.7000    0.6907       120

Macro F1: 0.6906751646140442
Weighted F1: 0.690675164614044
 
[Top Confusions]
jogging -> running : 9
jogging -> walking : 6
running -> walking : 5
walking -> running : 4
running -> jogging : 4
handwaving -> handclapping : 4
walking -> jogging : 2
handclapping -> handwaving : 2
 
[Per-class Table]
class            prec    rec     f1   supp
------------------------------------------
boxing          1.000  1.000  1.000     20
handclapping    0.818  0.900  0.857     20
handwaving      0.889  0.800  0.842     20
jogging         0.455  0.250  0.323     20
running         0.458  0.550  0.500     20
walking         0.560  0.700  0.622     20
 
[Training Curves]
epoch    tr_loss   tr_acc    va_loss   va_acc
----------------------------------------------
    1     1.7831   0.1797     1.7287   0.2963
    2     1.6941   0.3856     1.6392   0.4630
    3     1.5937   0.4575     1.5215   0.5370
    4     1.4722   0.4314     1.3956   0.5556
    5     1.3773   0.4314     1.2920   0.5000
    6     1.2692   0.4118     1.2091   0.6296
    7     1.1864   0.4869     1.1372   0.6111
    8     1.1346   0.4771     1.0735   0.6296
    9     1.0932   0.4804     0.9892   0.6296
   10     1.0282   0.5458     0.9022   0.6481
   11     0.9711   0.5294     0.8477   0.7222
   12     0.9163   0.5817     0.8069   0.7222
   13     0.8787   0.5719     0.7544   0.7037
   14     0.8689   0.5458     0.7227   0.6852
   15     0.8008   0.6569     0.6974   0.6852
   16     0.7890   0.6536     0.6792   0.7222
   17     0.8311   0.5980     0.6612   0.7407
   18     0.7894   0.6601     0.6381   0.7407
   19     0.7781   0.6373     0.6302   0.7407
   20     0.7520   0.6373     0.6224   0.7037
   21     0.7518   0.6438     0.6106   0.7407
   22     0.7217   0.6438     0.6006   0.7222
   23     0.6895   0.6732     0.6061   0.7407
   24     0.6883   0.6993     0.5965   0.7593
   25     0.6759   0.6993     0.5766   0.7593
   26     0.6458   0.7124     0.5632   0.7222
   27     0.6634   0.7255     0.5626   0.7222
   28     0.6289   0.7059     0.5491   0.7407
   29     0.6234   0.7092     0.5371   0.7407
   30     0.5918   0.7451     0.5434   0.7407
   31     0.5851   0.7320     0.5332   0.7407
   32     0.6119   0.7255     0.5156   0.8148
   33     0.5807   0.7288     0.5029   0.7778
   34     0.5459   0.7778     0.5100   0.7778
   35     0.5753   0.7418     0.4887   0.8333
   36     0.5203   0.7843     0.4777   0.7593
   37     0.5489   0.7516     0.4826   0.7593
   38     0.5109   0.7582     0.4667   0.7778
   39     0.5171   0.7745     0.4978   0.7778
   40     0.5197   0.7810     0.4572   0.7963
   41     0.4802   0.8007     0.4597   0.8148
   42     0.4977   0.7908     0.4523   0.7963
   43     0.4759   0.8203     0.4618   0.7963
   44     0.4792   0.8105     0.4613   0.8333
   45     0.4511   0.8039     0.4534   0.8333
   46     0.4451   0.8170     0.4733   0.7963
   47     0.4476   0.8072     0.4887   0.7593
 
