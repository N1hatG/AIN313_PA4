=== Shapelets + MLP (Random Shapelet Transform) ===
 
[Hyperparameters]
{
  "RANDOM_SEED": 42,
  "USE_CONF": true,
  "NUM_SHAPELETS": 64,
  "LEN_MIN": 40,
  "LEN_MAX": 80,
  "MAX_TRAIN_PER_CLASS": 60,
  "MLP_HIDDEN": [
    256,
    128
  ],
  "MLP_MAX_ITER": 200,
  "MLP_LR": 0.00115,
  "test_size": 0.2,
  "val_split": 0.15,
  "batch_size": 128,
  "weight_decay": 0.0001,
  "dropout": 0.2,
  "early_stopping_patience": 12,
  "BEST_VAL_ACC": 0.8148148148148148,
  "BEST_EPOCH": 39,
  "EPOCHS_RUN": 51,
  "CHECKPOINT_PATH": "C:\\Users\\User\\Desktop\\AIN313_PA4\\shapelets_mlp_results\\round_3_mlp_tuning\\20251227_152739_run06_K64_L40-80_cap60_conf1_mlp256x128_lr0.00115_ep200_seed42.pt",
  "MACRO_F1": 0.6916546416546416,
  "WEIGHTED_F1": 0.6916546416546417,
  "TOP_CONFUSIONS": "running -> jogging : 9\njogging -> running : 6\nhandwaving -> handclapping : 6\nrunning -> walking : 5\njogging -> walking : 4\nwalking -> running : 3\nhandclapping -> handwaving : 2\nwalking -> jogging : 1",
  "PER_CLASS_TABLE": "class            prec    rec     f1   supp\n------------------------------------------\nboxing          1.000  1.000  1.000     20\nhandclapping    0.750  0.900  0.818     20\nhandwaving      0.875  0.700  0.778     20\njogging         0.500  0.500  0.500     20\nrunning         0.400  0.300  0.343     20\nwalking         0.640  0.800  0.711     20",
  "TRAINING_CURVES": "epoch    tr_loss   tr_acc    va_loss   va_acc\n----------------------------------------------\n    1     1.7429   0.2026     1.5830   0.3519\n    2     1.5168   0.4183     1.4156   0.3704\n    3     1.3488   0.4183     1.2660   0.5000\n    4     1.1977   0.5000     1.1395   0.5370\n    5     1.0939   0.6046     1.0399   0.6481\n    6     1.0261   0.5784     0.9566   0.6111\n    7     0.9473   0.6144     0.8962   0.6667\n    8     0.8935   0.6242     0.8473   0.6852\n    9     0.8736   0.6078     0.7640   0.7037\n   10     0.8396   0.6144     0.7141   0.6852\n   11     0.7715   0.6569     0.6833   0.6852\n   12     0.7715   0.6503     0.6847   0.7222\n   13     0.7238   0.6830     0.6788   0.7222\n   14     0.7459   0.6830     0.6393   0.7222\n   15     0.7286   0.6634     0.6219   0.7222\n   16     0.6712   0.7255     0.6151   0.7037\n   17     0.6873   0.6732     0.6527   0.6667\n   18     0.6535   0.7320     0.6163   0.6852\n   19     0.6465   0.7386     0.5901   0.7593\n   20     0.6400   0.7124     0.5767   0.7593\n   21     0.6120   0.7059     0.5846   0.7593\n   22     0.5999   0.7712     0.5729   0.7037\n   23     0.5939   0.7549     0.5625   0.7593\n   24     0.5710   0.7745     0.5540   0.7593\n   25     0.5557   0.7680     0.5518   0.7222\n   26     0.5621   0.7549     0.5562   0.7222\n   27     0.5484   0.7712     0.5476   0.7407\n   28     0.5478   0.7876     0.5531   0.7963\n   29     0.5183   0.8007     0.5401   0.7407\n   30     0.5073   0.7908     0.5360   0.7222\n   31     0.5116   0.8072     0.5456   0.7778\n   32     0.4898   0.8137     0.5510   0.7593\n   33     0.4827   0.8170     0.5215   0.7778\n   34     0.4683   0.8039     0.5283   0.7407\n   35     0.4920   0.8039     0.5346   0.7407\n   36     0.4473   0.8268     0.5411   0.7407\n   37     0.4171   0.8399     0.5232   0.7778\n   38     0.4264   0.8464     0.5187   0.7778\n   39     0.4344   0.8203     0.5224   0.8148\n   40     0.4156   0.8399     0.5240   0.7778\n   41     0.4227   0.8464     0.5260   0.7778\n   42     0.4060   0.8529     0.5194   0.7593\n   43     0.3990   0.8301     0.5147   0.7963\n   44     0.3716   0.8529     0.5187   0.7222\n   45     0.4009   0.8366     0.5314   0.7593\n   46     0.3721   0.8399     0.5315   0.7593\n   47     0.3682   0.8725     0.5301   0.7963\n   48     0.3612   0.8627     0.5394   0.7593\n   49     0.3701   0.8529     0.5358   0.7407\n   50     0.3580   0.8301     0.5256   0.7593\n   51     0.3546   0.8464     0.5326   0.7778"
}
 
[Split / Data]
{
  "total_files": 599,
  "train_files_before_cap": 479,
  "test_files": 120,
  "train_sequences_after_cap": 360,
  "class_names": [
    "boxing",
    "handclapping",
    "handwaving",
    "jogging",
    "running",
    "walking"
  ]
}
 
[Timings (seconds)]
{
  "load_data": 0.7063,
  "sample_shapelets": 0.0059,
  "transform_train": 325.1367,
  "transform_test": 106.5309,
  "mlp_fit": 0.5696,
  "eval": 0.0076,
  "total": 432.961
}
 
[Accuracy]
0.700000

[Confusion Matrix]
            BX    HC    HW    JG    RN    WK
BX     |    20     0     0     0     0     0
HC     |     0    18     2     0     0     0
HW     |     0     6    14     0     0     0
JG     |     0     0     0    10     6     4
RN     |     0     0     0     9     6     5
WK     |     0     0     0     1     3    16
 
[Classification Report]
              precision    recall  f1-score   support

      boxing     1.0000    1.0000    1.0000        20
handclapping     0.7500    0.9000    0.8182        20
  handwaving     0.8750    0.7000    0.7778        20
     jogging     0.5000    0.5000    0.5000        20
     running     0.4000    0.3000    0.3429        20
     walking     0.6400    0.8000    0.7111        20

    accuracy                         0.7000       120
   macro avg     0.6942    0.7000    0.6917       120
weighted avg     0.6942    0.7000    0.6917       120

Macro F1: 0.6916546416546416
Weighted F1: 0.6916546416546417
 
[Top Confusions]
running -> jogging : 9
jogging -> running : 6
handwaving -> handclapping : 6
running -> walking : 5
jogging -> walking : 4
walking -> running : 3
handclapping -> handwaving : 2
walking -> jogging : 1
 
[Per-class Table]
class            prec    rec     f1   supp
------------------------------------------
boxing          1.000  1.000  1.000     20
handclapping    0.750  0.900  0.818     20
handwaving      0.875  0.700  0.778     20
jogging         0.500  0.500  0.500     20
running         0.400  0.300  0.343     20
walking         0.640  0.800  0.711     20
 
[Training Curves]
epoch    tr_loss   tr_acc    va_loss   va_acc
----------------------------------------------
    1     1.7429   0.2026     1.5830   0.3519
    2     1.5168   0.4183     1.4156   0.3704
    3     1.3488   0.4183     1.2660   0.5000
    4     1.1977   0.5000     1.1395   0.5370
    5     1.0939   0.6046     1.0399   0.6481
    6     1.0261   0.5784     0.9566   0.6111
    7     0.9473   0.6144     0.8962   0.6667
    8     0.8935   0.6242     0.8473   0.6852
    9     0.8736   0.6078     0.7640   0.7037
   10     0.8396   0.6144     0.7141   0.6852
   11     0.7715   0.6569     0.6833   0.6852
   12     0.7715   0.6503     0.6847   0.7222
   13     0.7238   0.6830     0.6788   0.7222
   14     0.7459   0.6830     0.6393   0.7222
   15     0.7286   0.6634     0.6219   0.7222
   16     0.6712   0.7255     0.6151   0.7037
   17     0.6873   0.6732     0.6527   0.6667
   18     0.6535   0.7320     0.6163   0.6852
   19     0.6465   0.7386     0.5901   0.7593
   20     0.6400   0.7124     0.5767   0.7593
   21     0.6120   0.7059     0.5846   0.7593
   22     0.5999   0.7712     0.5729   0.7037
   23     0.5939   0.7549     0.5625   0.7593
   24     0.5710   0.7745     0.5540   0.7593
   25     0.5557   0.7680     0.5518   0.7222
   26     0.5621   0.7549     0.5562   0.7222
   27     0.5484   0.7712     0.5476   0.7407
   28     0.5478   0.7876     0.5531   0.7963
   29     0.5183   0.8007     0.5401   0.7407
   30     0.5073   0.7908     0.5360   0.7222
   31     0.5116   0.8072     0.5456   0.7778
   32     0.4898   0.8137     0.5510   0.7593
   33     0.4827   0.8170     0.5215   0.7778
   34     0.4683   0.8039     0.5283   0.7407
   35     0.4920   0.8039     0.5346   0.7407
   36     0.4473   0.8268     0.5411   0.7407
   37     0.4171   0.8399     0.5232   0.7778
   38     0.4264   0.8464     0.5187   0.7778
   39     0.4344   0.8203     0.5224   0.8148
   40     0.4156   0.8399     0.5240   0.7778
   41     0.4227   0.8464     0.5260   0.7778
   42     0.4060   0.8529     0.5194   0.7593
   43     0.3990   0.8301     0.5147   0.7963
   44     0.3716   0.8529     0.5187   0.7222
   45     0.4009   0.8366     0.5314   0.7593
   46     0.3721   0.8399     0.5315   0.7593
   47     0.3682   0.8725     0.5301   0.7963
   48     0.3612   0.8627     0.5394   0.7593
   49     0.3701   0.8529     0.5358   0.7407
   50     0.3580   0.8301     0.5256   0.7593
   51     0.3546   0.8464     0.5326   0.7778
 
